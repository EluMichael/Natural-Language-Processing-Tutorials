{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webinar 4 - Project 1 Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part of speech tagger** reads text in some language and assigns parts of speech to each word in that text, such as noun, verb, adjective, etc.\n",
    "\n",
    "You must complete Steps 1-3 below to pass the project. We will go through each and learn some useful tips for doing the projects.\n",
    "- **Step 1:** Review the provided interface to load and access the text corpus\n",
    "- **Step 2:** Build a Most Frequent Class tagger to use as a baseline\n",
    "- **Step 3:** Build an HMM Part of Speech tagger and compare to the MFC baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "from helpers import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read and preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we are using in this project is a copy of the **Brown corpus** that has already been pre-processed to only include the **universal tagset**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = Dataset(tagfile = \"./tags-universal.txt\", \n",
    "               datafile = \"./brown-universal.txt\", \n",
    "               train_test_split = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the dataset\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data have the following structure to it:\n",
    "\n",
    "<p style=\"line-height: 25px;\">\n",
    "Dataset(sentences={<strong>'b100-5507'</strong>: Sentence(<strong>words</strong>=('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.'), <strong>tags</strong>=('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')), \n",
    "...)})\n",
    "</p>\n",
    "\n",
    "\n",
    "- **\"b100-5507\"**: ID of the sentence\n",
    "- **words**: Preprocessed tokens of the given sentence\n",
    "- **tags**: The label of each tokens in the given sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in the whole dataset:  57340\n",
      "Number of sentences in the training set:  45872\n",
      "Number of sentences in the test set:  11468\n"
     ]
    }
   ],
   "source": [
    "# Check the amount of sentences in the dataset\n",
    "print(\"Number of sentences in the whole dataset: \", len(data.sentences))\n",
    "print(\"Number of sentences in the training set: \", len(data.training_set.sentences))\n",
    "print(\"Number of sentences in the test set: \", len(data.testing_set.sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique vocabularies in the whole dataset:  56057\n",
      "Number of unique vocabularies in the training set:  50536\n",
      "Number of unique vocabularies in the test set:  25112\n"
     ]
    }
   ],
   "source": [
    "# Check the amount of unique vocabularies in the dataset\n",
    "print(\"Number of unique vocabularies in the whole dataset: \", len(data.vocab))\n",
    "print(\"Number of unique vocabularies in the training set: \", len(data.training_set.vocab))\n",
    "print(\"Number of unique vocabularies in the test set: \", len(data.testing_set.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Tags / Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will work with **12 tags** which we will use it as our labels. Tags are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of labels:  12\n",
      "Labels:  frozenset({'.', 'VERB', 'ADV', 'NUM', 'X', 'DET', 'NOUN', 'PRT', 'CONJ', 'ADJ', 'ADP', 'PRON'})\n"
     ]
    }
   ],
   "source": [
    "# Check the whole tagsets (labels or outputs)\n",
    "print(\"Total number of labels: \", len(data.tagset))\n",
    "print(\"Labels: \", data.tagset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Get a specific sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the tokens and tags of a specific ID. Let's see how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole sentence: \n",
      " Sentence(words=('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.'), tags=('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.'))\n",
      "-----------------------------------------------------------------------------\n",
      "Words: \n",
      " ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
      "-----------------------------------------------------------------------------\n",
      "Tags: \n",
      " ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n"
     ]
    }
   ],
   "source": [
    "# Get a sentence by its ID\n",
    "sentence_identifier = \"b100-5507\"\n",
    "\n",
    "print(\"The whole sentence: \\n\", data.sentences[sentence_identifier])\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Words: \\n\", data.sentences[sentence_identifier].words)\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Tags: \\n\", data.sentences[sentence_identifier].tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Get words and tags easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an easier way for getting words and tags in sentences which you can simply use **.X** or **.Y** on **data**, **training set**, or **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n"
     ]
    }
   ],
   "source": [
    "# Get the words in the first sentence\n",
    "print(data.X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n"
     ]
    }
   ],
   "source": [
    "# Get the tags in the first sentence\n",
    "print(data.Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Use .strem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.strem()** is another way for getting the words and tags but with this difference that we can use this only for doing iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  Mr.\n",
      "Tag:  NOUN\n",
      "\n",
      "Word:  Podger\n",
      "Tag:  NOUN\n",
      "\n",
      "Word:  had\n",
      "Tag:  VERB\n",
      "\n",
      "Word:  thanked\n",
      "Tag:  VERB\n",
      "\n",
      "Word:  him\n",
      "Tag:  PRON\n",
      "\n",
      "Word:  gravely\n",
      "Tag:  ADV\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (i_word, i_tag) in enumerate(data.stream()):\n",
    "    print(\"Word: \", i_word)\n",
    "    print(\"Tag: \", i_tag)\n",
    "    print(\"\")\n",
    "    if index == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Build a Most Frequent Class tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **3 TODOs** in this part which you have to complete:\n",
    "1. Write the **pair_counts** function\n",
    "2. Apply **pair_counts** to our training set\n",
    "3. Create a **mfc_table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Task 1 - Write the pair_counts function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "- Create an empty dictionary at the start so later on you will append all of the result into it.\n",
    "- Iterate through the sequence of tags. Also have the index of the exact iteration you are.\n",
    "    - Get the equivalent word in sequence of words using the index.\n",
    "    - Check to see if there is any tag inside the dictionary you have intialized at the start. \n",
    "        - If there wasn't any, They make it equal to an empty dictionary\n",
    "        - If there was then get that dictionary's value using the tag\n",
    "    - Check to see if the word we are in that iteration is inside the dictionary or not\n",
    "        - If there wans't then make it equal to 1\n",
    "        - If there was then add 1 to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Task 2 - Apply pair_counts to our training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "- Iterate through all tags and append all of them into one list\n",
    "- Iterate through all words and append all of them into one list\n",
    "- Apply pair_counts function for tags and words that you have just appended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input should look something similar to below (not totally exactly):**\n",
    "\n",
    "tags = ['NOUN',\n",
    " 'NOUN',\n",
    " 'VERB',\n",
    " 'VERB',\n",
    " 'PRON',\n",
    " 'ADV',\n",
    " '.', ...]\n",
    " \n",
    " words = ['Mr.',\n",
    " 'Podger',\n",
    " 'had',\n",
    " 'thanked',\n",
    " 'him',\n",
    " 'gravely',\n",
    " ',', ...]\n",
    " \n",
    " **Output should look something similar to below (not totally exactly):**\n",
    "\n",
    "{'NOUN': {'Mr.': 845,\n",
    "  'Podger': 22,\n",
    "  'use': 353,\n",
    "  'advice': 51,\n",
    "  'difference': 149,\n",
    "  'opinion': 95,\n",
    "  'board': 166,\n",
    "  'instrument': 45,\n",
    "  'elasticity': 6,\n",
    "  'pastes': 2, ...}, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Task 3 - Create a mfc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "- Initialize an empty dictionary for your mfc_table\n",
    "- Iterate through your pair_count items\n",
    "    - Consider the word in that loop as a key in the mfc_table dictionary\n",
    "    - Since there are multiple tags for each word, Then get the tag that has the maximum number and assign it as the value for that key (word) in your dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input should look something similar to below (not totally exactly):**\n",
    "\n",
    "dict_items([('Whenever', {'ADV': 13}), ('artists', {'NOUN': 35}), (',', {'.': 46500, 'X': 2}), ...])\n",
    " \n",
    "\n",
    "**Output should look something similar to below (not totally exactly):**\n",
    "\n",
    "{'Whenever': 'ADV',\n",
    " 'artists': 'NOUN',\n",
    " ',': '.',\n",
    " 'indeed': 'ADV',\n",
    " 'turned': 'VERB',\n",
    " 'to': 'PRT',\n",
    " 'actual': 'ADJ',\n",
    " 'representations': 'NOUN',\n",
    " 'or': 'CONJ', ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Build an HMM tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **10 TODOs** in this part which you have to complete:\n",
    "1. Build the **unigram_counts** function\n",
    "2. Apply **unigram_counts** function to tags on training set\n",
    "3. Build the **bigram_counts** function\n",
    "4. Apply **bigram_counts** function to tags on training set\n",
    "5. Build the **starting_counts** function\n",
    "6. Apply **starting_counts** to tags on training set\n",
    "7. Build the **ending_counts** function\n",
    "8. Apply **ending_counts** function to tags on training set\n",
    "9. Create states with **emission probability**\n",
    "10. **Add edges** or **transition probabilities** between states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Build the unigram_counts function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Initialize an empty dictionary\n",
    "- Iterate through sequences\n",
    "    - At each iteration, Check to see if the item in sequences is inside the dictioanty or not\n",
    "        - If there was then add 1 to it\n",
    "        - If there wasn't then make it equal to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Apply unigram_counts function to tags on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Iterate through data.stream and get each of tags\n",
    "- Apply unigram_counts to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input should look something similar to below (not totally exactly):**\n",
    "\n",
    "['NOUN',\n",
    " 'NOUN',\n",
    " 'VERB',\n",
    " 'VERB',\n",
    " 'PRON',\n",
    " 'ADV',\n",
    " '.',\n",
    " 'CONJ',\n",
    " 'ADV',\n",
    " 'PRON',\n",
    " 'VERB',\n",
    " 'NOUN',\n",
    " 'ADP',\n",
    " 'DET',\n",
    " 'NOUN', ...]\n",
    "\n",
    "**Output should look something similar to below (not totally exactly):**\n",
    "\n",
    "{'NOUN': 275558,\n",
    " 'VERB': 182750,\n",
    " 'PRON': 49334,\n",
    " 'ADV': 56239,\n",
    " '.': 147565,\n",
    " 'CONJ': 38151,\n",
    " ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Build the bigram_counts function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Initialize an empty dictionary\n",
    "- Get the bigrams of sequences using nltk library\n",
    "- Iterate through bigrams that you have just created\n",
    "    - At each iteration, Check to see if the item in sequences is inside the dictioanty or not\n",
    "        - If there was then add 1 to it\n",
    "        - If there wasn't then make it equal to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Apply bigram_counts function to tags on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Iterate through data.stream and save each of tags in a list\n",
    "- Apply unigram_counts to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input should look something similar to below (not totally exactly):**\n",
    "\n",
    "['NOUN',\n",
    " 'NOUN',\n",
    " 'VERB',\n",
    " 'VERB',\n",
    " 'PRON',\n",
    " 'ADV',\n",
    " '.',\n",
    " 'CONJ',\n",
    " 'ADV',\n",
    " 'PRON',\n",
    " 'VERB',\n",
    " 'NOUN',\n",
    " 'ADP',\n",
    " 'DET',\n",
    " 'NOUN', ...]\n",
    "\n",
    "**Output should look something similar to below (not totally exactly):**\n",
    "\n",
    "{('NOUN', 'NOUN'): 41295,\n",
    " ('NOUN', 'VERB'): 43802,\n",
    " ('VERB', 'VERB'): 33668,\n",
    " ('VERB', 'PRON'): 10075,\n",
    " ('PRON', 'ADV'): 2665,\n",
    " ('ADV', '.'): 9570,\n",
    " ('.', 'CONJ'): 12992, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Build the starting_counts function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Initialize an empty list (for appending the start tags)\n",
    "- Iterate through sequences\n",
    "    - Append the first tag in that loop's list to the empty list that we were initialized\n",
    "- Initialize an empty dictionary\n",
    "- Iterate through the list that you appended the start tags\n",
    "    - If the item in that loop is inside the dictionary then add up to 1\n",
    "    - If the item is not inside the dictionary then makt it equal to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Apply starting_counts to tags on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Get the tags inside the training set\n",
    "- Apply starting_counts to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input should look something similar to below (not totally exactly):**\n",
    "\n",
    "(('ADV',\n",
    "  'NOUN',\n",
    "  '.',\n",
    "  'ADV',\n",
    "  '.',\n",
    "  'VERB',\n",
    "  'ADP',\n",
    "  'ADJ',\n",
    "  'NOUN', ...), ...)\n",
    "\n",
    "**Output should look something similar to below (not totally exactly):**\n",
    "\n",
    "{'ADV': 4185,\n",
    " 'ADP': 5583,\n",
    " 'ADJ': 1582,\n",
    " 'PRT': 1718,\n",
    " 'DET': 9763,\n",
    " 'PRON': 7318,\n",
    " 'NOUN': 6469, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. Build the ending_counts function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Initialize an empty list (for appending the end tags)\n",
    "- Iterate through sequences \n",
    "    - Append the last tag in that loop's list to the empty list that we were initialized\n",
    "- Initialize an empty dictionary\n",
    "- Iterate through the list that you appended the last tags\n",
    "    - If the item in that loop is inside the dictionary then add up to 1\n",
    "    - If the item is not inside the dictionary then makt it equal to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. Apply ending_counts function to tags on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Get the tags inside the training set\n",
    "- Apply ending_counts to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input should look something similar to below (not totally exactly):**\n",
    "\n",
    "(('ADV',\n",
    "  'NOUN',\n",
    "  '.',\n",
    "  'ADV',\n",
    "  '.',\n",
    "  'VERB',\n",
    "  'ADP',\n",
    "  'ADJ',\n",
    "  'NOUN', ...), ...)\n",
    "\n",
    "**Output should look something similar to below (not totally exactly):**\n",
    "\n",
    "{'.': 44936,\n",
    " 'NOUN': 722,\n",
    " 'NUM': 63,\n",
    " 'VERB': 75,\n",
    " 'ADJ': 25,\n",
    " 'ADV': 16,\n",
    " 'ADP': 7, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9. Create states with emission probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways for approching such problem and here we will discuss only one of it. Below you can find some tips how to solve this:\n",
    "\n",
    "- Initialize an empty dictionary for states\n",
    "- Iterate through unique tags\n",
    "    - Initialize an empty dictionary for capturing emission probabilities for a specific tag\n",
    "    - Iterate through words and their occurance (in pair_counts). \n",
    "        - At each iteration, divide the occurace to the tag unigram of the tag in that loop and save it to the empty dictionary inside your first loop and consider word as its key.\n",
    "    - Get the discrete distribution of probabilities\n",
    "    - Add the distribtuion to a state\n",
    "    - Add state to states dictionary which you initialized at the start\n",
    "    - Add the state to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10. Add edges or transition probabilities between states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the start and end edges:\n",
    "- Iterate through the unique tags.\n",
    "    - Get the state for a specific tag from the states dictionary you created before\n",
    "    - Calculate the start tag probability by dividing the specific tag in tag_starts (that you created before) to sum of all values in tag_starts\n",
    "    - Add the start probability in between states to the model\n",
    "    - Calculate the end tag probability by dividing the specific tag in tag_ends (that you created before) to sum of all values in tag_ends\n",
    "    - Add the end tag probability in between states to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in between edges:\n",
    "- Iterate through the unique tags\n",
    "    - Get the state for a specific tag from the states dictionary you created before\n",
    "    - Initialze a sum of probabilities to 0\n",
    "    - Iterate through the unique tags for the second time\n",
    "        - Get the state for a specific tag from the states dictionary you created before for the second time\n",
    "        - Get the bigram of two tags. one from first loop the other one from second loop\n",
    "        - Calculate the transition probability\n",
    "        - Sum the transition probability to our sum_of_probabilities\n",
    "        - Add the transition to our model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
